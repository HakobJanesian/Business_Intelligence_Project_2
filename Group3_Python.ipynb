{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b4e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas.io.sql\n",
    "import xlrd\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import configparser\n",
    "import readconfig\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672a908",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d55dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ODBC Driver 17 for SQL Server']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Driver name\n",
    "\n",
    "driver_name = ''\n",
    "driver_names = [x for x in pyodbc.drivers() if x.endswith(' for SQL Server')]\n",
    "driver_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "054978d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "data = pd.read_excel('data_source.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19728a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x153c50a83d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to SQL\n",
    "\n",
    "engine = create_engine('mssql+pyodbc://@LAPTOP-T3G74HK4/Orders_RELATION_DB?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e95981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"C:/Users/PREDATOR/Desktop/AUA/Business Intelligence/Group Project 2\")\n",
    " \n",
    "\n",
    "conn_ER = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server};'\n",
    "                         'Server=LAPTOP-T3G74HK4;'\n",
    "                         'Database=Orders_RELATION_DB;'\n",
    "                         'Trusted_Connection=yes;')\n",
    "conn_DW = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server};'\n",
    "                         'Server=LAPTOP-T3G74HK4;'\n",
    "                         'Database=Orders_DIMENSIONAL_DB;'\n",
    "                         'Trusted_Connection=yes;')\n",
    "\n",
    "# Create a Cursor class instance for executing T-SQL statements\n",
    "cursor_ER = conn_ER.cursor()\n",
    "cursor_DW = conn_DW.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3d5df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate tables\n",
    "\n",
    "data[\"OrderDetails\"].to_sql('OrderDetails', con = engine, if_exists='replace', index = False)\n",
    "data[\"Orders\"].to_sql('Orders', con = engine, if_exists='replace', index = False)\n",
    "data[\"Products\"].to_sql('Products', con = engine, if_exists='replace', index = False)\n",
    "data[\"Shippers\"].to_sql('Shippers', con = engine, if_exists='replace', index = False)\n",
    "data[\"Customers\"].to_sql('Customers', con = engine, if_exists='replace', index = False)\n",
    "data[\"Suppliers\"].to_sql('Suppliers', con = engine, if_exists='replace', index = False)\n",
    "data[\"Categories\"].to_sql('Categories', con = engine, if_exists='replace', index = False)\n",
    "data[\"Customers\"].to_sql('Customers', con = engine, if_exists='replace', index = False)\n",
    "data[\"EmployeeTerritories\"].to_sql('EmployeeTerritories', con = engine, if_exists='replace', index = False)\n",
    "data[\"Employees\"].to_sql('Employees', con = engine, if_exists='replace', index = False)\n",
    "data[\"Territories\"].to_sql('Territories', con = engine, if_exists='replace', index = False)\n",
    "data[\"Region\"].to_sql('Region', con = engine, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a5a57",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d095488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine2 = create_engine('mssql+pyodbc://@LAPTOP-T3G74HK4/Orders_DIMENSIONAL_DB?driver=ODBC+Driver+17+for+SQL+Server')\n",
    "# connection2 = engine2.raw_connection()\n",
    "# cursor2 = connection2.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32cf2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tables names of the database (excluding system tables)    \n",
    "def extract_tables_db(cursor, *args):\n",
    "    results = []\n",
    "    for x in cursor.execute('exec sp_tables'):\n",
    "        if x[1] not in args:\n",
    "            results.append(x[2])\n",
    "    return results\n",
    "\n",
    "# Extract the column names of a table given it's name\n",
    "def extract_table_cols(cursor, table_name):\n",
    "    result = []\n",
    "    for row in cursor.columns(table=table_name):\n",
    "        result.append(row.column_name)\n",
    "    return result\n",
    "\n",
    "# A function for finding the primary key of a table\n",
    "def find_primary_key(cursor, table_name, schema):\n",
    "    \n",
    "    # Find the primary key information\n",
    "    table_primary_key =  cursor.primaryKeys(table_name, schema=schema)\n",
    "    \n",
    "    # Store the info about the PK constraint into a dictionary\n",
    "    columns = [column[0] for column in cursor.description]\n",
    "    results = []\n",
    "    for row in cursor.fetchall():\n",
    "        results.append(dict(zip(columns, row)))\n",
    "    try:\n",
    "        return results[0]\n",
    "    except:\n",
    "        pass\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de27902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_dim_scd1(cursor_src,cursor_dst, src_db, src_table, dst_db, dst_table,connect_col,\n",
    "                      src_schema = 'dbo', dst_schema = 'dbo',):\n",
    "    \n",
    "    # Set the proc name\n",
    "    proc_name = dst_db + '_'+ dst_table + '_SCD_ETL1'\n",
    "\n",
    "    # Create column lists\n",
    "    collist_insert = extract_table_cols(cursor_src, src_table)\n",
    "    collist_src = [\"SRC.\" + i for i in extract_table_cols(cursor_src, src_table)]\n",
    "    collist_dst = [\"DST.\" + i for i in extract_table_cols(cursor_dst, dst_table)][1:]\n",
    "\n",
    "    # Create a check string list\n",
    "    check_list = []\n",
    "    for i,j  in zip(collist_src, collist_dst):\n",
    "        check_list.append(f\"Isnull({j}, '') <> Isnull({i}, '')\")\n",
    "    check_str = \" OR \".join(check_list)\n",
    "\n",
    "    # Create a set string list\n",
    "    set_list = []\n",
    "    for i,j  in zip(collist_src, collist_dst):\n",
    "        set_list.append(f\"{j} = {i}\")\n",
    "    set_str = \",\".join(set_list)\n",
    "\n",
    "    sql_script_drop_proc = f\"\"\"\n",
    "    DROP PROCEDURE IF EXISTS {proc_name};\n",
    "    \"\"\"\n",
    "    sql_script_create_proc = f\"\"\"\n",
    "    CREATE PROCEDURE {proc_name}\n",
    "    AS\n",
    "    BEGIN TRY\n",
    "    MERGE {dst_db}.{dst_schema}.{dst_table} AS DST \n",
    "    USING {src_db}.{src_schema}.{src_table} AS SRC\n",
    "    ON ( SRC.{connect_col} = DST.{connect_col})\n",
    "    WHEN NOT MATCHED THEN \n",
    "    INSERT ({\",\".join(collist_insert)})\n",
    "    VALUES ({\",\".join(collist_src)})\n",
    "    WHEN MATCHED AND (\n",
    "        {check_str}\n",
    "        ) \n",
    "    THEN\n",
    "        UPDATE \n",
    "        SET \n",
    "            {set_str}; \n",
    "    END TRY\n",
    "    BEGIN CATCH\n",
    "        THROW\n",
    "    END CATCH\n",
    "    \"\"\"\n",
    "\n",
    "    # Dropping the proc if it exists and commiting the change\n",
    "    cursor_dst.execute(sql_script_drop_proc)\n",
    "    cursor_dst.commit()\n",
    "\n",
    "    # Creating a new procedure and committing the change\n",
    "    cursor_dst.execute(sql_script_create_proc)\n",
    "    cursor_dst.commit()\n",
    "\n",
    "    # Executing the created procedure\n",
    "    cursor_dst.execute(\"exec \" + dst_db + '.' + dst_schema + '.' + proc_name + ';')\n",
    "    cursor_dst.commit()\n",
    "\n",
    "    return f'The {dst_table} table of the {dst_db} database has been populated!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcaf2725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EmployeeID',\n",
       " 'LastName',\n",
       " 'FirstName',\n",
       " 'Title',\n",
       " 'TitleOfCourtesy',\n",
       " 'BirthDate',\n",
       " 'HireDate',\n",
       " 'Address',\n",
       " 'City',\n",
       " 'Region',\n",
       " 'PostalCode',\n",
       " 'Country',\n",
       " 'HomePhone',\n",
       " 'Extension',\n",
       " 'Notes',\n",
       " 'ReportsTo',\n",
       " 'PhotoPath']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_table_cols(cursor_ER, 'Employees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c963fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_dim_scd2(cursor_src,cursor_dst, src_db, src_table, dst_db, dst_table,connect_col,\n",
    "                      src_schema = 'dbo', dst_schema = 'dbo',):\n",
    "    \n",
    "    # Set the proc name\n",
    "    proc_name = dst_db + '_'+ dst_table + '_SCD_ETL2'\n",
    "\n",
    "    # Create column lists\n",
    "    collist_insert = extract_table_cols(cursor_src, src_table)\n",
    "    collist_insert2 = collist_insert\n",
    "    collist_src = [\"SRC.\" + i for i in extract_table_cols(cursor_src, src_table)]\n",
    "    collist_srcEXTRA = collist_src\n",
    "    collist_srcEXTRA.append('@Today')\n",
    "    collist_srcEXTRA.append('1')\n",
    "    collist_srcEXTRA2 = collist_src\n",
    "    collist_srcEXTRA2.append('ValidFrom')\n",
    "    collist_srcEXTRA2.append('IsCurrent')\n",
    "    collist_dst = [\"DST.\" + i for i in extract_table_cols(cursor_dst, dst_table)][1:]\n",
    "\n",
    "    # Create a check string list\n",
    "    check_list = []\n",
    "    for i,j  in zip(collist_src, collist_dst):\n",
    "        check_list.append(f\"Isnull({j}, '') <> Isnull({i}, '')\")\n",
    "    check_str = \" OR \".join(check_list)\n",
    "\n",
    "    # Create a set string list\n",
    "    set_list = []\n",
    "    for i,j  in zip(collist_src, collist_dst):\n",
    "        set_list.append(f\"{j} = {i}\")\n",
    "    set_str = \",\".join(set_list)\n",
    "\n",
    "    sql_script_drop_proc = f\"\"\"\n",
    "    DROP PROCEDURE IF EXISTS {proc_name};\n",
    "    \"\"\"\n",
    "    sql_script_create_proc = f\"\"\"\n",
    "    CREATE PROCEDURE {proc_name}\n",
    "    AS\n",
    "    BEGIN TRY\n",
    "    DECLARE @Yesterday INT = (YEAR(DATEADD(dd,-1,GETDATE())) * 10000) + (MONTH(DATEADD(dd,-1,GETDATE())) * 100) + DAY(DATEADD(dd,-1,GETDATE()))\n",
    "    DECLARE @Today INT = (YEAR(GETDATE()) * 10000) + (MONTH(GETDATE()) * 100) + DAY(GETDATE())\n",
    "    INSERT INTO {dst_db}.{dst_schema}.{dst_table}({\",\".join(collist_insert)})\n",
    "    SELECT {\",\".join(collist_insert)}\n",
    "    FROM\n",
    "    (\n",
    "    MERGE INTO {dst_db}.{dst_schema}.{dst_table} AS DST \n",
    "    USING {src_db}.{src_schema}.{src_table} AS SRC\n",
    "    ON ( SRC.{connect_col} = DST.{connect_col})\n",
    "    WHEN NOT MATCHED THEN\n",
    "    INSERT ({\",\".join(collist_srcEXTRA2)})\n",
    "    VALUES ({\",\".join(collist_srcEXTRA)})\n",
    "    WHEN MATCHED\n",
    "    AND IsCurrent = 1\n",
    "    AND (\n",
    "     ISNULL(DST.LastName,'') <> ISNULL(SRC.LastName,'') \n",
    "     OR ISNULL(DST.FirstName,'') <> ISNULL(SRC.FirstName,'') \n",
    "     OR ISNULL(DST.Title,'') <> ISNULL(SRC.Title,'')\n",
    "     OR ISNULL(DST.TitleOfCourtesy,'') <> ISNULL(SRC.TitleOfCourtesy,'')\n",
    "     OR ISNULL(DST.BirthDate,'') <> ISNULL(SRC.BirthDate,'')\n",
    "     OR ISNULL(DST.HireDate,'') <> ISNULL(SRC.HireDate,'')\n",
    "     OR ISNULL(DST.Address,'') <> ISNULL(SRC.Address,'')\n",
    "     OR ISNULL(DST.City,'') <> ISNULL(SRC.City,'')\n",
    "     OR ISNULL(DST.Region,'') <> ISNULL(SRC.Region,'')\n",
    "     OR ISNULL(DST.PostalCode,'') <> ISNULL(SRC.PostalCode,'')\n",
    "     OR ISNULL(DST.Country,'') <> ISNULL(SRC.Country,'')\n",
    "     OR ISNULL(DST.HomePhone,'') <> ISNULL(SRC.HomePhone,'')\n",
    "     OR ISNULL(DST.Extension,'') <> ISNULL(SRC.Extension,'')\n",
    "     OR ISNULL(DST.Notes,'') <> ISNULL(SRC.Notes,'')\n",
    "     OR ISNULL(DST.ReportsTo,'') <> ISNULL(SRC.ReportsTo,'')\n",
    "     OR ISNULL(DST.PhotoPath,'') <> ISNULL(SRC.PhotoPath,'')\n",
    "     )\n",
    "    THEN UPDATE \n",
    "    SET DST.IsCurrent = 0, DST.ValidTo = @Yesterday\n",
    "    OUTPUT SRC.EmployeeID, SRC.LastName, SRC.FirstName, SRC.Title, SRC.TitleOfCourtesy, SRC.BirthDate, SRC.HireDate, SRC.Address, SRC.City, SRC.Region, SRC.PostalCode, SRC.Country, SRC.HomePhone, SRC.Extension, SRC.Photo, SRC.Notes, SRC.ReportsTo, SRC.PhotoPath, $Action AS MergeAction\n",
    "    ) AS MRG\n",
    "    WHERE MRG.MergeAction = 'UPDATE'\n",
    "    ;\n",
    "    END TRY\n",
    "    BEGIN CATCH\n",
    "        THROW\n",
    "    END CATCH\n",
    "    \"\"\"\n",
    "\n",
    "    # Dropping the proc if it exists and commiting the change\n",
    "    cursor_dst.execute(sql_script_drop_proc)\n",
    "    cursor_dst.commit()\n",
    "\n",
    "    # Creating a new procedure and committing the change\n",
    "    cursor_dst.execute(sql_script_create_proc)\n",
    "    cursor_dst.commit()\n",
    "\n",
    "    # Executing the created procedure\n",
    "    cursor_dst.execute(\"exec \" + dst_db + '.' + dst_schema + '.' + proc_name + ';')\n",
    "    cursor_dst.commit()\n",
    "\n",
    "    return f'The {dst_table} table of the {dst_db} database has been populated!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "696022cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The DimShippers table of the Orders_DIMENSIONAL_DB database has been populated!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "populate_dim_scd1(cursor_ER, cursor_DW, src_db = 'Orders_RELATION_DB', src_table = 'Shippers',\n",
    "              dst_db = 'Orders_DIMENSIONAL_DB', dst_table = 'DimShippers',\n",
    "              connect_col = 'ShipperID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_dim_scd2(cursor_ER, cursor_DW, src_db = 'Orders_RELATION_DB', src_table = 'Employees',\n",
    "              dst_db = 'Orders_DIMENSIONAL_DB', dst_table = 'DimEmployee',\n",
    "              connect_col = 'EmployeeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "566d7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in cursor_DW.execute('SELECT * FROM DimShippers'):\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
